{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#install the necessary packages\n",
        "%pip install pdfplumber\n",
        "%pip install python-docx"
      ],
      "metadata": {
        "id": "kV0PySm7JDwx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de8ce8d-afe5-4ddd-bcf5-a27ba8e0c4a3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.8)\n",
            "Requirement already satisfied: pdfminer.six==20251107 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20251107)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (5.1.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (6.0.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "nQoKdrOHImNn"
      },
      "outputs": [],
      "source": [
        "#import the necessary libraries\n",
        "import os\n",
        "#refer to the \"create an ats scanner\" notes\n",
        "import pdfplumber\n",
        "#python-docx\n",
        "#Link: https://python-docx.readthedocs.io/en/latest/\n",
        "from docx import Document\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parser.py"
      ],
      "metadata": {
        "id": "btw2u9DCcQzK"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_file_type(filepath):\n",
        "  file_ext = os.path.splitext(filepath)[1].lower()\n",
        "  #return file_ext\n",
        "  if file_ext == \".pdf\":\n",
        "      return \"pdf\"\n",
        "  elif file_ext == \".docx\":\n",
        "      return \"docx\"\n",
        "  elif file_ext == \".txt\":\n",
        "      return \"txt\"\n",
        "  else:\n",
        "      return \"Unsupported resume format. Use either a .PDF, .DOCX, or .TXT file.\"\n",
        "\n",
        "def parse_pdf(filepath):\n",
        "  text = \"\"\n",
        "  with pdfplumber.open(filepath) as pdf:\n",
        "    for page in pdf.pages:\n",
        "      text += page.extract_text()\n",
        "  return text\n",
        "\n",
        "def parse_docx(filepath):\n",
        "  text = \"\"\n",
        "  doc = Document(filepath)\n",
        "  for paragraph in doc.paragraphs:\n",
        "    text += paragraph.text\n",
        "  return text\n",
        "\n",
        "def parse_txt(filepath):\n",
        "  with open(filepath, \"r\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "'''\n",
        "def clean_text(text):\n",
        "  text = text.replace(\"\\n\", \" \")\n",
        "'''\n",
        "\n",
        "def clean_text(text):\n",
        "  #step 1:\n",
        "  #step 1a. - remove \\r\n",
        "  cleaned = text.replace(\"\\r\", \"\")\n",
        "  #step 1b. - replace \\t with a space\n",
        "  cleaned = cleaned.replace(\"\\t\", \" \")\n",
        "\n",
        "  #step 2: replace the 3 main bullet point types with a - and a trailing space\n",
        "  #Ex. • Built SQL pipelines becomes - Built SQL pipelines\n",
        "  cleaned = cleaned.replace(\"•\", \"- \")\n",
        "  cleaned = cleaned.replace(\"●\", \"- \")\n",
        "  cleaned = cleaned.replace(\"\", \"- \")\n",
        "\n",
        "  #update 1/2 need to be worked on\n",
        "  #update 1: put email, phone and link on separate lines\n",
        "  #cleaned = re.sub(r\"\\s*-\\s*\", \"\\n\", cleaned)\n",
        "  #update 2: put job titles and employment date ranges on separate lines\n",
        "  #cleaned = re.sub(r\"(\\b\\d{4}\\b.*)\", r\"\\n\\1\", cleaned)\n",
        "\n",
        "  #step 3:\n",
        "  #step 3a. - split it into lines\n",
        "  lines = [line.strip() for line in cleaned.split(\"\\n\")]\n",
        "  #step 3b. - remove non-empty lines\n",
        "  lines = [line for line in lines if line]\n",
        "\n",
        "  cleaned = \"\\n\".join(lines)\n",
        "  return cleaned\n",
        "\n",
        "#main function that combines the previous functions\n",
        "def parse_resume(filepath):\n",
        "  #function 1\n",
        "  file_type = detect_file_type(filepath)\n",
        "  #functions 2,3,4\n",
        "  if file_type == \"pdf\":\n",
        "      raw_text = parse_pdf(filepath)\n",
        "  elif file_type == \"docx\":\n",
        "      raw_text = parse_docx(filepath)\n",
        "  elif file_type == \"txt\":\n",
        "      raw_text = parse_txt(filepath)\n",
        "  else:\n",
        "      raise ValueError(\"Unsupported resume format. Use either a .PDF, .DOCX, or .TXT file.\")\n",
        "\n",
        "  cleaned = clean_text(raw_text)\n",
        "\n",
        "  return {\n",
        "      \"file_name\": os.path.basename(filepath),\n",
        "      \"file_type\": file_type,\n",
        "      \"raw_text\": raw_text,\n",
        "      \"clean_text\": cleaned\n",
        "  }"
      ],
      "metadata": {
        "id": "JYPVDaSDJD3U"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#detect_file_type(\"example.pdf\")\n",
        "#parse_pdf(\"example.pdf\")\n",
        "#clean_text(parse_pdf(\"example.pdf\"))\n",
        "#print(clean_text(parse_pdf(\"example.pdf\")))\n",
        "#parse_resume(\"example.pdf\")"
      ],
      "metadata": {
        "id": "y8nDJiMNK1nd"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#jd_parser.py"
      ],
      "metadata": {
        "id": "MVQcC7eILTqK"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the necessary libraries\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "zEkfxX2Mj0-B"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read the job description\n",
        "def load_jd(filepath):\n",
        "  with open(filepath, \"r\") as f:\n",
        "    text = f.read()\n",
        "    return text\n",
        "\n",
        "#normalize and clean the text\n",
        "def clean_jd_text(text):\n",
        "  #step 1:\n",
        "  #step 1a. - remove \\r\n",
        "  cleaned = text.replace(\"\\r\", \"\")\n",
        "  #step 1b. - replace \\t with a space\n",
        "  cleaned = cleaned.replace(\"\\t\", \" \")\n",
        "\n",
        "  #step 2: replace the 3 main bullet point types with a - and a trailing space\n",
        "  #Ex. • Built SQL pipelines becomes - Built SQL pipelines\n",
        "  cleaned = cleaned.replace(\"•\", \"- \")\n",
        "  cleaned = cleaned.replace(\"●\", \"- \")\n",
        "  cleaned = cleaned.replace(\"\", \"- \")\n",
        "\n",
        "  #update 1/2 need to be worked on\n",
        "  #update 1: put email, phone and link on separate lines\n",
        "  #cleaned = re.sub(r\"\\s*-\\s*\", \"\\n\", cleaned)\n",
        "  #update 2: put job titles and employment date ranges on separate lines\n",
        "  #cleaned = re.sub(r\"(\\b\\d{4}\\b.*)\", r\"\\n\\1\", cleaned)\n",
        "\n",
        "  #step 3:\n",
        "  #step 3a. - split it into lines\n",
        "  lines = [line.strip() for line in cleaned.split(\"\\n\")]\n",
        "  #step 3b. - remove non-empty lines\n",
        "  lines = [line for line in lines if line]\n",
        "\n",
        "  cleaned = \"\\n\".join(lines)\n",
        "  return cleaned\n",
        "\n",
        "#grab the job title\n",
        "def extract_job_title(text):\n",
        "  first_line = text.split(\"\\n\")[0]\n",
        "  job_title = first_line.strip()\n",
        "  return job_title\n",
        "\n",
        "#identify the required and preferred skills - from my own personal experience\n",
        "def extract_skills(text):\n",
        "  required = []\n",
        "  preferred = []\n",
        "  return {\n",
        "      \"required_skills\": required,\n",
        "      \"preferred_skills\": preferred,\n",
        "      \"all_skills\": required + preferred\n",
        "  }\n",
        "\n",
        "#grab the experience needed for the role - years and seniority\n",
        "def extract_experience_requirements(text):\n",
        "  experience_years = None\n",
        "  seniority = None\n",
        "  return {\n",
        "      \"experience_years\": experience_years,\n",
        "      \"seniority\": seniority\n",
        "  }\n",
        "\n",
        "#extract job responsibilities\n",
        "def extract_job_responsibilities(text):\n",
        "  responsibilities = []\n",
        "  for line in text.split(\"\\n\"):\n",
        "    if line.startswith(\"-\") or line.startswith(\"*\"):\n",
        "      responsibilities.append(line)\n",
        "  return responsibilities\n",
        "\n",
        "#main function that combines the previous functions\n",
        "def parse_jd(filepath):\n",
        "    raw_text = load_jd(filepath)\n",
        "    clean_text = clean_jd_text(raw_text)\n",
        "\n",
        "    title = extract_job_title(clean_text)\n",
        "    skill_data = extract_skills(clean_text)\n",
        "    experience_data = extract_experience_requirements(clean_text)\n",
        "    responsibilities = extract_job_responsibilities(clean_text)\n",
        "\n",
        "    return {\n",
        "        \"file_name\": os.path.basename(filepath),\n",
        "        \"raw_text\": raw_text,\n",
        "        \"clean_text\": clean_text,\n",
        "        \"job_title\": title,\n",
        "        \"required_skills\": skill_data[\"required_skills\"],\n",
        "        \"preferred_skills\": skill_data[\"preferred_skills\"],\n",
        "        \"all_skills\": skill_data[\"all_skills\"],\n",
        "        \"responsibilities\": responsibilities,\n",
        "        \"min_experience_years\": experience_data[\"experience_years\"],\n",
        "        \"seniority\": experience_data[\"seniority\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "kJVv1gNqksK4"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = load_jd(\"sample_jd_1.txt\")\n",
        "#print(text)"
      ],
      "metadata": {
        "id": "_TUc9HIJlqJB"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text = clean_jd_text(text)\n",
        "#cleaned_text"
      ],
      "metadata": {
        "id": "_F8pE98rowA3"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_title = extract_job_title(cleaned_text)\n",
        "#print(job_title)"
      ],
      "metadata": {
        "id": "-cUvmD-3pDuq"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_skills = extract_skills(cleaned_text)\n",
        "#print(job_skills)"
      ],
      "metadata": {
        "id": "UpjcLlJqp5U8"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_experience_requirements = extract_experience_requirements(cleaned_text)\n",
        "#print(job_experience_requirements)"
      ],
      "metadata": {
        "id": "MYYd2cIUqJd7"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_resposibilities = extract_job_responsibilities(cleaned_text)\n",
        "#print(job_resposibilities)"
      ],
      "metadata": {
        "id": "V3xMExFjqUmT"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_result = parse_jd(\"sample_jd_1.txt\")\n",
        "#print(job_result)"
      ],
      "metadata": {
        "id": "xkw74i-IqfBp"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y3PEEMXhqr4I"
      },
      "execution_count": 88,
      "outputs": []
    }
  ]
}